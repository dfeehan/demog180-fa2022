{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aging-subscriber",
   "metadata": {},
   "source": [
    "# Calculate Your Social Networks Grade!\n",
    "\n",
    "Fill in the appropriate numbers below, they are accurate as of October 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change this cell\n",
    "lab_weight = 0.2\n",
    "hw_weight = 0.3\n",
    "midterm_weight = 0.2\n",
    "final_weight = 0.25\n",
    "quiz_weight = 0.05\n",
    "assert(lab_weight + hw_weight + midterm_weight + final_weight + quiz_weight == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the following as needed\n",
    "num_labs = 5\n",
    "num_hws = 5\n",
    "num_quizzes = 0\n",
    "\n",
    "possible_points = lab_weight + hw_weight + midterm_weight #+ final_weight + quiz_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-payment",
   "metadata": {},
   "source": [
    "## Labs\n",
    "\n",
    "Fill in your lab scores by adding together your autograder and manual scores.  \n",
    "**Don't forget to factor in later labs if you're using this notebook past October!**  \n",
    "Also, there's no need to include lab 0 because that lab was not for credit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab1 = .../9.0\n",
    "lab2 = .../9.0\n",
    "lab3 = .../12.0\n",
    "lab4 = .../13.0\n",
    "lab5 = .../11.0\n",
    "\n",
    "labs = [lab1, lab2, lab3, lab4, lab5] \n",
    "\n",
    "lab_score = sum(labs) / num_labs\n",
    "lab_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-yellow",
   "metadata": {},
   "source": [
    "## Homeworks\n",
    "\n",
    "Fill in your homework scores.  \n",
    "**Don't forget to factor in later homeworks if you're using this notebook past October!**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw1 = .../7.0\n",
    "hw2 = .../24.0\n",
    "hw3 = .../13.0\n",
    "hw4 = .../20.0\n",
    "hw5 = .../30.0\n",
    "\n",
    "hws = [hw1, hw2, hw3, hw4, hw5] \n",
    "\n",
    "#drop the lowest hw score\n",
    "hws.remove(min(hws))\n",
    "\n",
    "hw_score = sum(hws) / (num_hws - 1)\n",
    "hw_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-intake",
   "metadata": {},
   "source": [
    "## Midterm\n",
    "\n",
    "Fill in your midterm score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "midterm = .../56.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-beatles",
   "metadata": {},
   "source": [
    "## Final\n",
    "\n",
    "Fill in your (predicted) final score as a decimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = .../..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-fifty",
   "metadata": {},
   "source": [
    "## Quizzes\n",
    "\n",
    "Fill in your (predicted) quiz scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz1 = .../...\n",
    "...\n",
    "\n",
    "#make a list of quizzes\n",
    "quizzes = [quiz1, ...]\n",
    "\n",
    "quiz_score = sum(quizzes) / num_quizzes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-nancy",
   "metadata": {},
   "source": [
    "## Calculate your score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_labs = lab_score * lab_weight\n",
    "weighted_hws = hw_score * hw_weight\n",
    "weighted_midterm = midterm * midterm_weight\n",
    "#weighted_final = final * final_weight\n",
    "#weighted_quizzes = quizzes * quiz_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_grade_current_assignments = (weighted_labs + weighted_hws + weighted_midterm) / possible_points * 100\n",
    "\n",
    "#final_grade_final = ((weighted_labs + weighted_hws + weighted_midterm + weighted_final + weighted_quizzes) / 1.0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_grade_current_assignments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
